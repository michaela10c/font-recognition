{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression \n",
    "(data filtered out into 4 categories: bold & italic, bold & nonitalic, nonbold & italic, nonbold & nonitalic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UH9CmY4sxfKh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UPntOYJwx68Y"
   },
   "outputs": [],
   "source": [
    "Trainfile = pandas.read_csv('train_data.csv')\n",
    "Trainlabels = pandas.read_csv('train_labels.csv')\n",
    "Testfile = pandas.read_csv('test_data.csv')\n",
    "X_train = Trainfile.values\n",
    "Y_train = Trainlabels.values\n",
    "X_test = Testfile.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dBnJNkcyDdq",
    "outputId": "2cd09aa7-fa45-4a89-dc97-5808ccf0bb9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjyP_-3UyENJ",
    "outputId": "a2d761f6-bd8f-4b06-87d2-8cf406ec997e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65000, 407)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZGAbIR63xjoi"
   },
   "outputs": [],
   "source": [
    "def train_and_test(model, filename, print=False):\n",
    "    model.fit(X_train, Y_train.flatten())\n",
    "    if print:\n",
    "        print('training accuracy:', accuracy_score(model.predict(X_train), Y_train.flatten()))\n",
    "    Y_test_pred = model.predict(X_test).astype(object)\n",
    "    np.savetxt(filename, np.dstack((np.arange(1, Y_test_pred.size+1),Y_test_pred))[0],\"%d,%s\",header=\"ID,Font\",comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ooMXzIxPx0qX"
   },
   "outputs": [],
   "source": [
    "# get examples (x,y) that are bold and italic and its indices\n",
    "def filter_boldanditalic(x,y=None):\n",
    "    i = np.where((x[:,1] == 0.7) & (x[:,2] == 1.))\n",
    "    return (x[i], y[i], i) if y is not None else (x[i], i)\n",
    "\n",
    "# get examples (x,y) that are bold and nonitalic and its indices\n",
    "def filter_boldandnonitalic(x,y=None):\n",
    "    i = np.where((x[:,1] == 0.7) & (x[:,2] == 0.))\n",
    "    return (x[i], y[i], i) if y is not None else (x[i], i)\n",
    "\n",
    "# get examples (x,y) that are nonbold and italic and its indices\n",
    "def filter_nonboldanditalic(x,y=None):\n",
    "    i = np.where((x[:,1] == 0.4) & (x[:,2] == 1.))\n",
    "    return (x[i], y[i], i) if y is not None else (x[i], i)\n",
    "\n",
    "# get examples (x,y) that are nonbold and nonitalic and its indices\n",
    "def filter_nonboldandnonitalic(x,y=None):\n",
    "    i = np.where((x[:,1] == 0.4) & (x[:,2] == 0.))\n",
    "    return (x[i], y[i], i) if y is not None else (x[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r_cIk5DayHlF"
   },
   "outputs": [],
   "source": [
    "# filter train data into 4 cases: bold,italic=[(1,1), (0,1), (1,0), (0,0)]\n",
    "X_train_bolditalic, Y_train_bolditalic, _ = filter_boldanditalic(X_train, Y_train)\n",
    "X_train_boldnonitalic, Y_train_boldnonitalic, _ = filter_boldandnonitalic(X_train, Y_train)\n",
    "X_train_nonbolditalic, Y_train_nonbolditalic, _ = filter_nonboldanditalic(X_train, Y_train)\n",
    "X_train_nonboldnonitalic, Y_train_nonboldnonitalic, _ = filter_nonboldandnonitalic(X_train, Y_train)\n",
    "\n",
    "# filter test data into 4 cases: bold,italic=[(1,1), (0,1), (1,0), (0,0)]\n",
    "X_test_bolditalic, bi = filter_boldanditalic(X_test)\n",
    "X_test_boldnonitalic, bni = filter_boldandnonitalic(X_test)\n",
    "X_test_nonbolditalic, nbi = filter_nonboldanditalic(X_test)\n",
    "X_test_nonboldnonitalic, nbni = filter_nonboldandnonitalic(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hG57r1-gyJZr"
   },
   "outputs": [],
   "source": [
    "# standard normalization\n",
    "def normalize_std(X):\n",
    "    return (X - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "\n",
    "X_train_bolditalic = normalize_std(X_train_bolditalic)\n",
    "X_train_boldnonitalic = normalize_std(X_train_boldnonitalic)\n",
    "X_train_nonbolditalic = normalize_std(X_train_nonbolditalic)\n",
    "X_train_nonboldnonitalic = normalize_std(X_train_nonboldnonitalic)\n",
    "\n",
    "X_test_bolditalic = normalize_std(X_test_bolditalic)\n",
    "X_test_boldnonitalic = normalize_std(X_test_boldnonitalic)\n",
    "X_test_nonbolditalic = normalize_std(X_test_nonbolditalic)\n",
    "X_test_nonboldnonitalic = normalize_std(X_test_nonboldnonitalic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zgiE8XCyL-o",
    "outputId": "32343bfc-ee80-4117-f5e0-4177ef9210b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bold and italic train accuracy: 0.6125482766159003\n",
      "bold and nonitalic train accuracy: 0.508389375721758\n",
      "nonbold and italic train accuracy: 0.608834873735536\n",
      "nonbold and nonitalic train accuracy: 0.5920227920227921\n",
      "\u001b[1mLogistic Regression training accuracy: 0.5809692307692308\n"
     ]
    }
   ],
   "source": [
    "# 1. bold and italic\n",
    "lr = linear_model.LogisticRegression(multi_class='multinomial', max_iter=4000)\n",
    "lr.fit(X_train_bolditalic[:,3:], Y_train_bolditalic.flatten())\n",
    "acc_a = metrics.accuracy_score(Y_train_bolditalic.flatten(), lr.predict(X_train_bolditalic[:,3:])) \n",
    "print('bold and italic train accuracy:', acc_a) \n",
    "Y_test_bi = lr.predict(X_test_bolditalic[:,3:])\n",
    "\n",
    "# 2. bold and non-italic\n",
    "lr = linear_model.LogisticRegression(multi_class='multinomial', max_iter=4000)\n",
    "lr.fit(X_train_boldnonitalic[:,3:], Y_train_boldnonitalic.flatten())\n",
    "acc_b = metrics.accuracy_score(Y_train_boldnonitalic.flatten(), lr.predict(X_train_boldnonitalic[:,3:])) \n",
    "print('bold and nonitalic train accuracy:', acc_b)  \n",
    "Y_test_bni = lr.predict(X_test_boldnonitalic[:,3:])\n",
    "\n",
    "# 3. non-bold and italic\n",
    "lr = linear_model.LogisticRegression(multi_class='multinomial', max_iter=4000)\n",
    "lr.fit(X_train_nonbolditalic[:,3:], Y_train_nonbolditalic.flatten())\n",
    "acc_c = metrics.accuracy_score(Y_train_nonbolditalic.flatten(), lr.predict(X_train_nonbolditalic[:,3:])) \n",
    "print('nonbold and italic train accuracy:', acc_c)\n",
    "Y_test_nbi = lr.predict(X_test_nonbolditalic[:,3:])\n",
    "\n",
    "# 4. non-bold and non-italic\n",
    "lr = linear_model.LogisticRegression(multi_class='multinomial', max_iter=4000)\n",
    "lr.fit(X_train_nonboldnonitalic[:,3:], Y_train_nonboldnonitalic.flatten())\n",
    "acc_d = metrics.accuracy_score(Y_train_nonboldnonitalic.flatten(), lr.predict(X_train_nonboldnonitalic[:,3:]))\n",
    "print('nonbold and nonitalic train accuracy:', acc_d) \n",
    "Y_test_nbni = lr.predict(X_test_nonboldnonitalic[:,3:])\n",
    "\n",
    "# TOTAL TRAINING ACCURACY: 58.09692307692308%\n",
    "num_correct_exs = acc_a*len(Y_train_bolditalic) + acc_b*len(Y_train_boldnonitalic) + acc_c*len(Y_train_nonbolditalic) + acc_d*len(Y_train_nonboldnonitalic)\n",
    "print('\\033[1mLogistic Regression training accuracy:', num_correct_exs / len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "v_SaV_MlzVNF"
   },
   "outputs": [],
   "source": [
    "i_bi = 0\n",
    "i_nbi = 0\n",
    "i_bni = 0\n",
    "i_nbni = 0\n",
    "\n",
    "Y_test_pred = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    if i in bi[0]:\n",
    "        Y_test_pred.append(Y_test_bi[i_bi])\n",
    "        i_bi+=1\n",
    "    elif i in bni[0]:\n",
    "        Y_test_pred.append(Y_test_bni[i_bni])\n",
    "        i_bni+=1\n",
    "    elif i in nbni[0]:\n",
    "        Y_test_pred.append(Y_test_nbni[i_nbni])\n",
    "        i_nbni+=1\n",
    "    else:\n",
    "        Y_test_pred.append(Y_test_nbi[i_nbi])\n",
    "        i_nbi+=1\n",
    "    i+=1\n",
    "\n",
    "# write to file! \n",
    "Y_test_pred = np.array(Y_test_pred).astype(object)\n",
    "np.savetxt('lr.csv', np.dstack((np.arange(1, Y_test_pred.size+1),Y_test_pred))[0],\"%d,%s\",header=\"ID,Font\",comments=\"\")\n",
    "\n",
    "# TEST ACCURACY: 52.553%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4nMQ2tUE0i4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29221, 407)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "logistic_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
